{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SwinForImageClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alalbiol/anaconda3/envs/CursoTransformers/lib/python3.10/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /home/conda/feedstock_root/build_artifacts/pytorch-recipe_1664412099808/work/aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Some weights of SwinForImageClassification were not initialized from the model checkpoint at microsoft/swin-tiny-patch4-window7-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import  SwinModel\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "model = SwinForImageClassification.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\",\n",
    "    num_labels=2,\n",
    "    ignore_mismatched_sizes = True,)\n",
    "\n",
    "#inputs = feature_extractor(image, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinForImageClassification(\n",
      "  (swin): SwinModel(\n",
      "    (embeddings): SwinEmbeddings(\n",
      "      (patch_embeddings): SwinPatchEmbeddings(\n",
      "        (projection): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "      )\n",
      "      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (encoder): SwinEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): SwinStage(\n",
      "          (blocks): ModuleList(\n",
      "            (0): SwinLayer(\n",
      "              (layernorm_before): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): SwinAttention(\n",
      "                (self): SwinSelfAttention(\n",
      "                  (query): Linear(in_features=96, out_features=96, bias=True)\n",
      "                  (key): Linear(in_features=96, out_features=96, bias=True)\n",
      "                  (value): Linear(in_features=96, out_features=96, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): SwinSelfOutput(\n",
      "                  (dense): Linear(in_features=96, out_features=96, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_path): SwinDropPath(p=0.1)\n",
      "              (layernorm_after): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "              (intermediate): SwinIntermediate(\n",
      "                (dense): Linear(in_features=96, out_features=384, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): SwinOutput(\n",
      "                (dense): Linear(in_features=384, out_features=96, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (1): SwinLayer(\n",
      "              (layernorm_before): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): SwinAttention(\n",
      "                (self): SwinSelfAttention(\n",
      "                  (query): Linear(in_features=96, out_features=96, bias=True)\n",
      "                  (key): Linear(in_features=96, out_features=96, bias=True)\n",
      "                  (value): Linear(in_features=96, out_features=96, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): SwinSelfOutput(\n",
      "                  (dense): Linear(in_features=96, out_features=96, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_path): SwinDropPath(p=0.1)\n",
      "              (layernorm_after): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "              (intermediate): SwinIntermediate(\n",
      "                (dense): Linear(in_features=96, out_features=384, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): SwinOutput(\n",
      "                (dense): Linear(in_features=384, out_features=96, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (downsample): SwinPatchMerging(\n",
      "            (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
      "            (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinStage(\n",
      "          (blocks): ModuleList(\n",
      "            (0): SwinLayer(\n",
      "              (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): SwinAttention(\n",
      "                (self): SwinSelfAttention(\n",
      "                  (query): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (key): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (value): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): SwinSelfOutput(\n",
      "                  (dense): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_path): SwinDropPath(p=0.1)\n",
      "              (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              (intermediate): SwinIntermediate(\n",
      "                (dense): Linear(in_features=192, out_features=768, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): SwinOutput(\n",
      "                (dense): Linear(in_features=768, out_features=192, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (1): SwinLayer(\n",
      "              (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): SwinAttention(\n",
      "                (self): SwinSelfAttention(\n",
      "                  (query): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (key): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (value): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): SwinSelfOutput(\n",
      "                  (dense): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_path): SwinDropPath(p=0.1)\n",
      "              (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              (intermediate): SwinIntermediate(\n",
      "                (dense): Linear(in_features=192, out_features=768, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): SwinOutput(\n",
      "                (dense): Linear(in_features=768, out_features=192, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (downsample): SwinPatchMerging(\n",
      "            (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
      "            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (2): SwinStage(\n",
      "          (blocks): ModuleList(\n",
      "            (0): SwinLayer(\n",
      "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): SwinAttention(\n",
      "                (self): SwinSelfAttention(\n",
      "                  (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): SwinSelfOutput(\n",
      "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_path): SwinDropPath(p=0.1)\n",
      "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (intermediate): SwinIntermediate(\n",
      "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): SwinOutput(\n",
      "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (1): SwinLayer(\n",
      "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): SwinAttention(\n",
      "                (self): SwinSelfAttention(\n",
      "                  (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): SwinSelfOutput(\n",
      "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_path): SwinDropPath(p=0.1)\n",
      "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (intermediate): SwinIntermediate(\n",
      "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): SwinOutput(\n",
      "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (2): SwinLayer(\n",
      "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): SwinAttention(\n",
      "                (self): SwinSelfAttention(\n",
      "                  (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): SwinSelfOutput(\n",
      "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_path): SwinDropPath(p=0.1)\n",
      "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (intermediate): SwinIntermediate(\n",
      "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): SwinOutput(\n",
      "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (3): SwinLayer(\n",
      "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): SwinAttention(\n",
      "                (self): SwinSelfAttention(\n",
      "                  (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): SwinSelfOutput(\n",
      "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_path): SwinDropPath(p=0.1)\n",
      "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (intermediate): SwinIntermediate(\n",
      "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): SwinOutput(\n",
      "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (4): SwinLayer(\n",
      "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): SwinAttention(\n",
      "                (self): SwinSelfAttention(\n",
      "                  (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): SwinSelfOutput(\n",
      "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_path): SwinDropPath(p=0.1)\n",
      "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (intermediate): SwinIntermediate(\n",
      "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): SwinOutput(\n",
      "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (5): SwinLayer(\n",
      "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): SwinAttention(\n",
      "                (self): SwinSelfAttention(\n",
      "                  (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): SwinSelfOutput(\n",
      "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_path): SwinDropPath(p=0.1)\n",
      "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (intermediate): SwinIntermediate(\n",
      "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): SwinOutput(\n",
      "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (downsample): SwinPatchMerging(\n",
      "            (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
      "            (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (3): SwinStage(\n",
      "          (blocks): ModuleList(\n",
      "            (0): SwinLayer(\n",
      "              (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): SwinAttention(\n",
      "                (self): SwinSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): SwinSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_path): SwinDropPath(p=0.1)\n",
      "              (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (intermediate): SwinIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): SwinOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (1): SwinLayer(\n",
      "              (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): SwinAttention(\n",
      "                (self): SwinSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): SwinSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_path): SwinDropPath(p=0.1)\n",
      "              (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (intermediate): SwinIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): SwinOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (pooler): AdaptiveAvgPool1d(output_size=1)\n",
      "  )\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Resize(size=(384, 384), interpolation=bicubic, max_size=None, antialias=None)\n",
      "    CenterCrop(size=(384, 384))\n",
      "    ToTensor()\n",
      "    Normalize(mean=tensor([0.5000, 0.5000, 0.5000]), std=tensor([0.5000, 0.5000, 0.5000]))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#pip install --pre timm\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "import timm.data\n",
    "#https://huggingface.co/timm/maxvit_base_tf_384.in1k\n",
    "\n",
    "img = Image.open(\n",
    "    urlopen('https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'))\n",
    "\n",
    "model = timm.create_model('maxvit_base_tf_384.in1k', pretrained=True, )\n",
    "model = model.eval()\n",
    "\n",
    "data_cfg = timm.data.resolve_data_config(model.pretrained_cfg)\n",
    "transform = timm.data.create_transform(**data_cfg)\n",
    "print(transform)\n",
    "\n",
    "output = model(transform(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "top5_probabilities, top5_class_indices = torch.topk(output.softmax(dim=1) * 100, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxxVit(\n",
      "  (stem): Stem(\n",
      "    (conv1): Conv2dSame(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (norm1): BatchNormAct2d(\n",
      "      64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "      (drop): Identity()\n",
      "      (act): GELUTanh()\n",
      "    )\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (stages): Sequential(\n",
      "    (0): MaxxVitStage(\n",
      "      (blocks): Sequential(\n",
      "        (0): MaxxVitBlock(\n",
      "          (conv): MbConvBlock(\n",
      "            (shortcut): Downsample2d(\n",
      "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
      "              (expand): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (pre_norm): BatchNormAct2d(\n",
      "              64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (down): Identity()\n",
      "            (conv1_1x1): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm1): BatchNormAct2d(\n",
      "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (conv2_kxk): Conv2dSame(384, 384, kernel_size=(3, 3), stride=(2, 2), groups=384, bias=False)\n",
      "            (norm2): BatchNormAct2d(\n",
      "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (se): SEModule(\n",
      "              (fc1): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "              (fc2): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv3_1x1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (attn_block): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "          (attn_grid): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (1): MaxxVitBlock(\n",
      "          (conv): MbConvBlock(\n",
      "            (shortcut): Identity()\n",
      "            (pre_norm): BatchNormAct2d(\n",
      "              96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (down): Identity()\n",
      "            (conv1_1x1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm1): BatchNormAct2d(\n",
      "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (conv2_kxk): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "            (norm2): BatchNormAct2d(\n",
      "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (se): SEModule(\n",
      "              (fc1): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "              (fc2): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv3_1x1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (attn_block): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "          (attn_grid): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): MaxxVitStage(\n",
      "      (blocks): Sequential(\n",
      "        (0): MaxxVitBlock(\n",
      "          (conv): MbConvBlock(\n",
      "            (shortcut): Downsample2d(\n",
      "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
      "              (expand): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (pre_norm): BatchNormAct2d(\n",
      "              96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (down): Identity()\n",
      "            (conv1_1x1): Conv2d(96, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm1): BatchNormAct2d(\n",
      "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (conv2_kxk): Conv2dSame(768, 768, kernel_size=(3, 3), stride=(2, 2), groups=768, bias=False)\n",
      "            (norm2): BatchNormAct2d(\n",
      "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (se): SEModule(\n",
      "              (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "              (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (attn_block): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "          (attn_grid): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (1): MaxxVitBlock(\n",
      "          (conv): MbConvBlock(\n",
      "            (shortcut): Identity()\n",
      "            (pre_norm): BatchNormAct2d(\n",
      "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (down): Identity()\n",
      "            (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm1): BatchNormAct2d(\n",
      "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "            (norm2): BatchNormAct2d(\n",
      "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (se): SEModule(\n",
      "              (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "              (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (attn_block): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "          (attn_grid): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (2): MaxxVitBlock(\n",
      "          (conv): MbConvBlock(\n",
      "            (shortcut): Identity()\n",
      "            (pre_norm): BatchNormAct2d(\n",
      "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (down): Identity()\n",
      "            (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm1): BatchNormAct2d(\n",
      "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "            (norm2): BatchNormAct2d(\n",
      "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (se): SEModule(\n",
      "              (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "              (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (attn_block): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "          (attn_grid): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (3): MaxxVitBlock(\n",
      "          (conv): MbConvBlock(\n",
      "            (shortcut): Identity()\n",
      "            (pre_norm): BatchNormAct2d(\n",
      "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (down): Identity()\n",
      "            (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm1): BatchNormAct2d(\n",
      "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "            (norm2): BatchNormAct2d(\n",
      "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (se): SEModule(\n",
      "              (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "              (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (attn_block): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "          (attn_grid): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (4): MaxxVitBlock(\n",
      "          (conv): MbConvBlock(\n",
      "            (shortcut): Identity()\n",
      "            (pre_norm): BatchNormAct2d(\n",
      "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (down): Identity()\n",
      "            (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm1): BatchNormAct2d(\n",
      "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "            (norm2): BatchNormAct2d(\n",
      "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (se): SEModule(\n",
      "              (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "              (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (attn_block): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "          (attn_grid): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (5): MaxxVitBlock(\n",
      "          (conv): MbConvBlock(\n",
      "            (shortcut): Identity()\n",
      "            (pre_norm): BatchNormAct2d(\n",
      "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (down): Identity()\n",
      "            (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm1): BatchNormAct2d(\n",
      "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "            (norm2): BatchNormAct2d(\n",
      "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (se): SEModule(\n",
      "              (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "              (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (attn_block): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "          (attn_grid): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): MaxxVitStage(\n",
      "      (blocks): Sequential(\n",
      "        (0): MaxxVitBlock(\n",
      "          (conv): MbConvBlock(\n",
      "            (shortcut): Downsample2d(\n",
      "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
      "              (expand): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (pre_norm): BatchNormAct2d(\n",
      "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (down): Identity()\n",
      "            (conv1_1x1): Conv2d(192, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm1): BatchNormAct2d(\n",
      "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (conv2_kxk): Conv2dSame(1536, 1536, kernel_size=(3, 3), stride=(2, 2), groups=1536, bias=False)\n",
      "            (norm2): BatchNormAct2d(\n",
      "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (se): SEModule(\n",
      "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (attn_block): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "          (attn_grid): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (1): MaxxVitBlock(\n",
      "          (conv): MbConvBlock(\n",
      "            (shortcut): Identity()\n",
      "            (pre_norm): BatchNormAct2d(\n",
      "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (down): Identity()\n",
      "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm1): BatchNormAct2d(\n",
      "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "            (norm2): BatchNormAct2d(\n",
      "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (se): SEModule(\n",
      "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (attn_block): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "          (attn_grid): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (2): MaxxVitBlock(\n",
      "          (conv): MbConvBlock(\n",
      "            (shortcut): Identity()\n",
      "            (pre_norm): BatchNormAct2d(\n",
      "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (down): Identity()\n",
      "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm1): BatchNormAct2d(\n",
      "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "            (norm2): BatchNormAct2d(\n",
      "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (se): SEModule(\n",
      "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (attn_block): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "          (attn_grid): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (3): MaxxVitBlock(\n",
      "          (conv): MbConvBlock(\n",
      "            (shortcut): Identity()\n",
      "            (pre_norm): BatchNormAct2d(\n",
      "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (down): Identity()\n",
      "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm1): BatchNormAct2d(\n",
      "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "            (norm2): BatchNormAct2d(\n",
      "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (se): SEModule(\n",
      "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (attn_block): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "          (attn_grid): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (4): MaxxVitBlock(\n",
      "          (conv): MbConvBlock(\n",
      "            (shortcut): Identity()\n",
      "            (pre_norm): BatchNormAct2d(\n",
      "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (down): Identity()\n",
      "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm1): BatchNormAct2d(\n",
      "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "            (norm2): BatchNormAct2d(\n",
      "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (se): SEModule(\n",
      "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (attn_block): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "          (attn_grid): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (5): MaxxVitBlock(\n",
      "          (conv): MbConvBlock(\n",
      "            (shortcut): Identity()\n",
      "            (pre_norm): BatchNormAct2d(\n",
      "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (down): Identity()\n",
      "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm1): BatchNormAct2d(\n",
      "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "            (norm2): BatchNormAct2d(\n",
      "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (se): SEModule(\n",
      "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (attn_block): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "          (attn_grid): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (6): MaxxVitBlock(\n",
      "          (conv): MbConvBlock(\n",
      "            (shortcut): Identity()\n",
      "            (pre_norm): BatchNormAct2d(\n",
      "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (down): Identity()\n",
      "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm1): BatchNormAct2d(\n",
      "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "            (norm2): BatchNormAct2d(\n",
      "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (se): SEModule(\n",
      "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (attn_block): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "          (attn_grid): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (7): MaxxVitBlock(\n",
      "          (conv): MbConvBlock(\n",
      "            (shortcut): Identity()\n",
      "            (pre_norm): BatchNormAct2d(\n",
      "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (down): Identity()\n",
      "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm1): BatchNormAct2d(\n",
      "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "            (norm2): BatchNormAct2d(\n",
      "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (se): SEModule(\n",
      "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (attn_block): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "          (attn_grid): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (8): MaxxVitBlock(\n",
      "          (conv): MbConvBlock(\n",
      "            (shortcut): Identity()\n",
      "            (pre_norm): BatchNormAct2d(\n",
      "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (down): Identity()\n",
      "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm1): BatchNormAct2d(\n",
      "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "            (norm2): BatchNormAct2d(\n",
      "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (se): SEModule(\n",
      "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (attn_block): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "          (attn_grid): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (9): MaxxVitBlock(\n",
      "          (conv): MbConvBlock(\n",
      "            (shortcut): Identity()\n",
      "            (pre_norm): BatchNormAct2d(\n",
      "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (down): Identity()\n",
      "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm1): BatchNormAct2d(\n",
      "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "            (norm2): BatchNormAct2d(\n",
      "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (se): SEModule(\n",
      "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (attn_block): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "          (attn_grid): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (10): MaxxVitBlock(\n",
      "          (conv): MbConvBlock(\n",
      "            (shortcut): Identity()\n",
      "            (pre_norm): BatchNormAct2d(\n",
      "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (down): Identity()\n",
      "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm1): BatchNormAct2d(\n",
      "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "            (norm2): BatchNormAct2d(\n",
      "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (se): SEModule(\n",
      "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (attn_block): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "          (attn_grid): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (11): MaxxVitBlock(\n",
      "          (conv): MbConvBlock(\n",
      "            (shortcut): Identity()\n",
      "            (pre_norm): BatchNormAct2d(\n",
      "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (down): Identity()\n",
      "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm1): BatchNormAct2d(\n",
      "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "            (norm2): BatchNormAct2d(\n",
      "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (se): SEModule(\n",
      "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (attn_block): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "          (attn_grid): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (12): MaxxVitBlock(\n",
      "          (conv): MbConvBlock(\n",
      "            (shortcut): Identity()\n",
      "            (pre_norm): BatchNormAct2d(\n",
      "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (down): Identity()\n",
      "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm1): BatchNormAct2d(\n",
      "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "            (norm2): BatchNormAct2d(\n",
      "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (se): SEModule(\n",
      "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (attn_block): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "          (attn_grid): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (13): MaxxVitBlock(\n",
      "          (conv): MbConvBlock(\n",
      "            (shortcut): Identity()\n",
      "            (pre_norm): BatchNormAct2d(\n",
      "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (down): Identity()\n",
      "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm1): BatchNormAct2d(\n",
      "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "            (norm2): BatchNormAct2d(\n",
      "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (se): SEModule(\n",
      "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (attn_block): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "          (attn_grid): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): MaxxVitStage(\n",
      "      (blocks): Sequential(\n",
      "        (0): MaxxVitBlock(\n",
      "          (conv): MbConvBlock(\n",
      "            (shortcut): Downsample2d(\n",
      "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
      "              (expand): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (pre_norm): BatchNormAct2d(\n",
      "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (down): Identity()\n",
      "            (conv1_1x1): Conv2d(384, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm1): BatchNormAct2d(\n",
      "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (conv2_kxk): Conv2dSame(3072, 3072, kernel_size=(3, 3), stride=(2, 2), groups=3072, bias=False)\n",
      "            (norm2): BatchNormAct2d(\n",
      "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (se): SEModule(\n",
      "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (attn_block): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "          (attn_grid): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (1): MaxxVitBlock(\n",
      "          (conv): MbConvBlock(\n",
      "            (shortcut): Identity()\n",
      "            (pre_norm): BatchNormAct2d(\n",
      "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (down): Identity()\n",
      "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm1): BatchNormAct2d(\n",
      "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
      "            (norm2): BatchNormAct2d(\n",
      "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (se): SEModule(\n",
      "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (attn_block): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "          (attn_grid): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): Identity()\n",
      "  (head): NormMlpHead(\n",
      "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Identity())\n",
      "    (norm): LayerNorm2d((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (pre_logits): Sequential(\n",
      "      (fc): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (act): Tanh()\n",
      "    )\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MaxxVit' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m timm\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mresolve_data_config(model)\n",
      "File \u001b[0;32m~/anaconda3/envs/CursoTransformers/lib/python3.10/site-packages/timm/data/config.py:22\u001b[0m, in \u001b[0;36mresolve_data_config\u001b[0;34m(args, default_cfg, model, use_test_size, verbose)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39m# Resolve input/image size\u001b[39;00m\n\u001b[1;32m     21\u001b[0m in_chans \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m\n\u001b[0;32m---> 22\u001b[0m \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39m\u001b[39mchans\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     in_chans \u001b[39m=\u001b[39m args[\u001b[39m'\u001b[39m\u001b[39mchans\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     25\u001b[0m input_size \u001b[39m=\u001b[39m (in_chans, \u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/CursoTransformers/lib/python3.10/site-packages/torch/nn/modules/module.py:1207\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1206\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1207\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1208\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MaxxVit' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "timm.data.config.resolve_data_config(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': '',\n",
       " 'hf_hub_id': 'timm/maxvit_base_tf_384.in1k',\n",
       " 'architecture': 'maxvit_base_tf_384',\n",
       " 'tag': 'in1k',\n",
       " 'custom_load': False,\n",
       " 'input_size': (3, 384, 384),\n",
       " 'fixed_input_size': True,\n",
       " 'interpolation': 'bicubic',\n",
       " 'crop_pct': 1.0,\n",
       " 'crop_mode': 'squash',\n",
       " 'mean': (0.5, 0.5, 0.5),\n",
       " 'std': (0.5, 0.5, 0.5),\n",
       " 'num_classes': 1000,\n",
       " 'pool_size': (7, 7),\n",
       " 'first_conv': 'stem.conv1',\n",
       " 'classifier': 'head.fc'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pretrained_cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DefaultCfg(tags=deque(['in1k', 'in21k_ft_in1k']), cfgs={'in1k': PretrainedCfg(url='', file=None, hf_hub_id='timm/maxvit_base_tf_384.in1k', hf_hub_filename=None, source=None, architecture=None, tag=None, custom_load=False, input_size=(3, 384, 384), test_input_size=None, min_input_size=None, fixed_input_size=True, interpolation='bicubic', crop_pct=1.0, test_crop_pct=None, crop_mode='squash', mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), num_classes=1000, label_offset=None, pool_size=(7, 7), test_pool_size=None, first_conv='stem.conv1', classifier='head.fc', license=None, description=None, origin_url=None, paper_name=None, paper_ids=None, notes=None), 'in21k_ft_in1k': PretrainedCfg(url='', file=None, hf_hub_id='timm/maxvit_base_tf_384.in21k_ft_in1k', hf_hub_filename=None, source=None, architecture=None, tag=None, custom_load=False, input_size=(3, 384, 384), test_input_size=None, min_input_size=None, fixed_input_size=True, interpolation='bicubic', crop_pct=1.0, test_crop_pct=None, crop_mode='squash', mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), num_classes=1000, label_offset=None, pool_size=(7, 7), test_pool_size=None, first_conv='stem.conv1', classifier='head.fc', license=None, description=None, origin_url=None, paper_name=None, paper_ids=None, notes=None)}, is_pretrained=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=(384, 384), interpolation=bicubic, max_size=None, antialias=None)\n",
       "    CenterCrop(size=(384, 384))\n",
       "    ToTensor()\n",
       "    Normalize(mean=tensor([0.5000, 0.5000, 0.5000]), std=tensor([0.5000, 0.5000, 0.5000]))\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaxxVit(\n",
       "  (stem): Stem(\n",
       "    (conv1): Conv2dSame(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (norm1): BatchNormAct2d(\n",
       "      64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "      (drop): Identity()\n",
       "      (act): GELUTanh()\n",
       "    )\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (stages): Sequential(\n",
       "    (0): MaxxVitStage(\n",
       "      (blocks): Sequential(\n",
       "        (0): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Downsample2d(\n",
       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "              (expand): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2dSame(384, 384, kernel_size=(3, 3), stride=(2, 2), groups=384, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): MaxxVitStage(\n",
       "      (blocks): Sequential(\n",
       "        (0): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Downsample2d(\n",
       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "              (expand): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(96, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2dSame(768, 768, kernel_size=(3, 3), stride=(2, 2), groups=768, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (2): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (3): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (4): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (5): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): MaxxVitStage(\n",
       "      (blocks): Sequential(\n",
       "        (0): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Downsample2d(\n",
       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "              (expand): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(192, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2dSame(1536, 1536, kernel_size=(3, 3), stride=(2, 2), groups=1536, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (2): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (3): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (4): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (5): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (6): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (7): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (8): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (9): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (10): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (11): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (12): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (13): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): MaxxVitStage(\n",
       "      (blocks): Sequential(\n",
       "        (0): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Downsample2d(\n",
       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "              (expand): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(384, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2dSame(3072, 3072, kernel_size=(3, 3), stride=(2, 2), groups=3072, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): Identity()\n",
       "  (head): NormMlpHead(\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Identity())\n",
       "    (norm): LayerNorm2d((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (pre_logits): Sequential(\n",
       "      (fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (act): Tanh()\n",
       "    )\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CursoTransformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "332768db682295b8dac3c4a901a1fe1343c13865b4033bb10f86fd07133ed44e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
